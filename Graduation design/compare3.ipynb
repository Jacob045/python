{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import read_filepath_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定两种数据源的路径\n",
    "# 微波辐射计数据时段包含探空气球数据的时段,所以由探空气球代表的的世界时追踪微波辐射计代表的北京时\n",
    "Year = '2008'\n",
    "Filepath = r'I:\\Data\\Personal Data\\graduation project\\SACOL'\n",
    "# ↓探空气球数据\n",
    "filepath_1 = Filepath + '\\Balloon'\n",
    "Target_str_1 = 'UPAR'+Year\n",
    "# ↓微波辐射计数据\n",
    "filepath_2 = Filepath + '\\microwave'\n",
    "Target_str_2 = 'lv2_'+Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    北京时 = 世界时 + 8\n",
    "    此函数的功能就是将世界时转换为对应的北京时，\n",
    "'''\n",
    "def f_trans(str):\n",
    "    if(str == '0000'):\n",
    "        return('0800')\n",
    "    elif(str == '1200'):\n",
    "        return('2000')\n",
    "    else:\n",
    "        return('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data(filepath):\n",
    "    # data_1是气球探空数据\n",
    "    data_1 = pd.read_csv(filepath)\n",
    "    # data_2 暂时存储同一时间的匹配数据\n",
    "    data_2 = pd.DataFrame()\n",
    "    output_data = pd.DataFrame()\n",
    "    i = 0\n",
    "    while i < data_1.shape[0]:\n",
    "    # while i < 1:\n",
    "        # 清空绘图数据\n",
    "        data_2.drop(data_2.index, inplace=True)\n",
    "        data_2 = data_2.append(data_1.loc[i:i,])\n",
    "        file_search_point = 'lv2_'+str(data_1.loc[i:i,'Time'].values)[2:8]\n",
    "        file_search_path = filepath_2 + '\\\\' + str(data_1.loc[i:i,'Time'].values)[2:6] +'\\\\' + file_search_point + '.csv'\n",
    "        if(os.path.exists(file_search_path)):\n",
    "            # data_3 载入搜索文件\n",
    "            # 搜索并标记\n",
    "            data_3 = pd.read_csv(file_search_path)\n",
    "            data_3.rename(columns={'Date/Time':'Time'},inplace=True)\n",
    "            # 转换搜索点\n",
    "            trans_point = str(data_1.loc[i:i,'Time'].values)[2:10] + '_WT' + f_trans(str(data_1.loc[i:i,'Time'].values)[14:18])\n",
    "            j = -1\n",
    "            flag = -1\n",
    "            # 遍历搜索文件寻找搜索点\n",
    "            while j < data_3.shape[0]-1:\n",
    "                j = j + 1\n",
    "                T = str(data_3.loc[j:j,'Time'].values)[2:17]\n",
    "                if(T == trans_point):\n",
    "                    flag = j\n",
    "                    data_2 = data_2.append(data_3.loc[j:j,])\n",
    "                # else:\n",
    "                #     print(trans_point[0:8]+'_BjT'+trans_point[11:18] +' NO exists!')\n",
    "                #     print(T+'\\n')\n",
    "        # -----------------------------------------------------------\n",
    "            if(flag == -1):\n",
    "                print('No compare data:'+trans_point)\n",
    "                # print('No compare data: '+trans_point[0:8]+'_BjT'+trans_point[11:18])\n",
    "                break\n",
    "            else:\n",
    "                output_data = output_data.append(data_2)\n",
    "                print('Ready to find: '+trans_point)\n",
    "                # print('Ready to find: '+trans_point[0:8]+'_BjT'+trans_point[11:18])\n",
    "        else:\n",
    "            print('No exits '+ file_search_path+'\\n')\n",
    "            break\n",
    "        i = i + 1\n",
    "    output_data = output_data.round(2)\n",
    "    return(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ready to find: 20080102_WT2000\n",
      "Ready to find: 20080103_WT0800\n",
      "Ready to find: 20080117_WT0800\n",
      "Ready to find: 20080118_WT2000\n",
      "Ready to find: 20080128_WT2000\n",
      "Ready to find: 20080129_WT0800\n",
      "Ready to find: 20080129_WT2000\n",
      "No compare data:20080130_WT0800\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200801.csv\n",
      "Ready to find: 20080201_WT0800\n",
      "Ready to find: 20080204_WT2000\n",
      "Ready to find: 20080208_WT2000\n",
      "Ready to find: 20080209_WT0800\n",
      "Ready to find: 20080213_WT2000\n",
      "Ready to find: 20080219_WT2000\n",
      "Ready to find: 20080226_WT0800\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200802.csv\n",
      "Ready to find: 20080306_WT0800\n",
      "Ready to find: 20080323_WT2000\n",
      "Ready to find: 20080324_WT0800\n",
      "Ready to find: 20080325_WT2000\n",
      "Ready to find: 20080331_WT2000\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200803.csv\n",
      "Ready to find: 20080406_WT2000\n",
      "Ready to find: 20080413_WT2000\n",
      "Ready to find: 20080414_WT0800\n",
      "Ready to find: 20080414_WT2000\n",
      "Ready to find: 20080415_WT0800\n",
      "Ready to find: 20080415_WT2000\n",
      "Ready to find: 20080416_WT0800\n",
      "Ready to find: 20080416_WT2000\n",
      "Ready to find: 20080417_WT0800\n",
      "Ready to find: 20080417_WT2000\n",
      "Ready to find: 20080418_WT0800\n",
      "Ready to find: 20080418_WT2000\n",
      "Ready to find: 20080419_WT0800\n",
      "Ready to find: 20080419_WT2000\n",
      "Ready to find: 20080420_WT0800\n",
      "Ready to find: 20080420_WT2000\n",
      "Ready to find: 20080421_WT0800\n",
      "Ready to find: 20080421_WT2000\n",
      "Ready to find: 20080422_WT0800\n",
      "Ready to find: 20080422_WT2000\n",
      "Ready to find: 20080423_WT0800\n",
      "Ready to find: 20080424_WT0800\n",
      "Ready to find: 20080424_WT2000\n",
      "Ready to find: 20080425_WT0800\n",
      "Ready to find: 20080425_WT2000\n",
      "Ready to find: 20080426_WT0800\n",
      "Ready to find: 20080426_WT2000\n",
      "Ready to find: 20080427_WT0800\n",
      "Ready to find: 20080427_WT2000\n",
      "Ready to find: 20080428_WT0800\n",
      "Ready to find: 20080428_WT2000\n",
      "Ready to find: 20080429_WT0800\n",
      "Ready to find: 20080429_WT2000\n",
      "Ready to find: 20080430_WT0800\n",
      "Ready to find: 20080430_WT2000\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200804.csv\n",
      "Ready to find: 20080501_WT0800\n",
      "Ready to find: 20080501_WT2000\n",
      "Ready to find: 20080502_WT0800\n",
      "Ready to find: 20080502_WT2000\n",
      "Ready to find: 20080503_WT0800\n",
      "Ready to find: 20080503_WT2000\n",
      "Ready to find: 20080504_WT0800\n",
      "Ready to find: 20080504_WT2000\n",
      "Ready to find: 20080505_WT0800\n",
      "Ready to find: 20080505_WT2000\n",
      "Ready to find: 20080506_WT0800\n",
      "Ready to find: 20080506_WT2000\n",
      "Ready to find: 20080507_WT0800\n",
      "Ready to find: 20080507_WT2000\n",
      "Ready to find: 20080508_WT0800\n",
      "Ready to find: 20080508_WT2000\n",
      "Ready to find: 20080509_WT0800\n",
      "Ready to find: 20080509_WT2000\n",
      "Ready to find: 20080510_WT0800\n",
      "Ready to find: 20080511_WT0800\n",
      "Ready to find: 20080511_WT2000\n",
      "Ready to find: 20080512_WT0800\n",
      "Ready to find: 20080512_WT2000\n",
      "Ready to find: 20080513_WT0800\n",
      "Ready to find: 20080513_WT2000\n",
      "Ready to find: 20080514_WT0800\n",
      "Ready to find: 20080514_WT2000\n",
      "Ready to find: 20080515_WT0800\n",
      "Ready to find: 20080515_WT2000\n",
      "Ready to find: 20080516_WT0800\n",
      "Ready to find: 20080516_WT2000\n",
      "Ready to find: 20080517_WT0800\n",
      "Ready to find: 20080517_WT2000\n",
      "Ready to find: 20080518_WT0800\n",
      "No compare data:20080518_WTError\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200805.csv\n",
      "Ready to find: 20080601_WT0800\n",
      "No compare data:20080601_WT2000\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200806.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200807.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200807.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200808.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200808.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200809.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200809.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200810.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200810.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200811.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200811.csv\n",
      "No exits I:\\Data\\Personal Data\\graduation project\\SACOL\\microwave\\2008\\lv2_200812.csv\n",
      "\n",
      "Finish:I:\\Data\\Personal Data\\graduation project\\SACOL\\Balloon\\2008\\UPAR200812.csv\n"
     ]
    }
   ],
   "source": [
    "# 气球探空数据\n",
    "L1_filepaths = read_filepath_module.read_filepath(filepath_1,Target_str_1)\n",
    "# 微波辐射计探空数据\n",
    "L2_filepaths = read_filepath_module.read_filepath(filepath_2,Target_str_2)\n",
    "data = pd.DataFrame()\n",
    "for L1_filepath in L1_filepaths:\n",
    "    data = data.append(search_data(L1_filepath))\n",
    "    print('Finish:'+L1_filepath)\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "# data.to_csv(r'H:\\桌面\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = 1\n",
    "# while col<data.shape[1]:\n",
    "#     row = 0\n",
    "#     while row<data.shape[0]:\n",
    "#         data.iloc[row:row+1,col:col+1] = (data.iloc[row:row+1,col:col+1]>350)\n",
    "#         row=row+1\n",
    "#     col=col+1\n",
    "# row = 502\n",
    "# col = 4\n",
    "# print(False in (data.iloc[row:row+1,col:col+1]>350).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row(row):\n",
    "    # flag = flag + 1\n",
    "    if(row&1 == 0):\n",
    "        data.drop([row,row+1],inplace=True)\n",
    "        print(f'Have already delete {row} and {row+1}')\n",
    "    else:\n",
    "        data.drop([row-1,row],inplace=True)\n",
    "        print(f'Have already delete {row-1} and {row}')\n",
    "#---------------------------------------------------------\n",
    "flag = 0\n",
    "col = 1\n",
    "while col<data.shape[1]:\n",
    "    #print('col'+str(col))\n",
    "    row = 0\n",
    "    data.reset_index(inplace=True,drop=True)\n",
    "    while row<data.shape[0]:\n",
    "        # print('    row'+str(row))\n",
    "        # print(data.iloc[row:row+1,col:col+1])\n",
    "        if(str(data.iloc[row:row+1,col:col+1].values)[2:5] == 'nan'):\n",
    "            print('NaN')\n",
    "            print(row,col)\n",
    "            delete_row(row)\n",
    "            if(row&1 ==0):\n",
    "                row = row + 2\n",
    "            else:\n",
    "                row = row + 1\n",
    "        elif(True in (data.iloc[row:row+1,col:col+1]>350).values):\n",
    "            print(row,col)\n",
    "            delete_row(row)\n",
    "            if(row&1 ==0):\n",
    "                row = row + 2\n",
    "            else:\n",
    "                row = row + 1\n",
    "        else:\n",
    "            row = row + 1\n",
    "    col = col + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(df):\n",
    "    npdata =np.array(df)\n",
    "    # print(npdata)\n",
    "    row = 0\n",
    "    sum = 0\n",
    "    while row<npdata.shape[0]:\n",
    "        sum = sum + (npdata[row:row+1,:]-npdata[row+1:row+2,:]) ** 2\n",
    "        # print(npdata[row:row+1,:])\n",
    "        # print(npdata[row+1:row+2,:])\n",
    "        row = row + 2\n",
    "    MSE_data = sum/npdata.shape[0]\n",
    "    return(MSE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17.75]]\n[[20.23]]\n[[19.42]]\n[[15.21]]\n[[10.57]]\n[[7.58]]\n[[6.05]]\n[[5.3]]\n[[5.85]]\n[[5.98]]\n[[6.02]]\n[[7.27]]\n[[5.87]]\n[[4.31]]\n[[4.53]]\n[[7.35]]\n[[9.8]]\n[[12.19]]\n[[15.3]]\n[[18.08]]\n[[23.02]]\n[[24.44]]\n[[26.04]]\n[[27.3]]\n[[28.85]]\n[[28.53]]\n[[28.91]]\n[[28.97]]\n[[25.29]]\n[[22.91]]\n[[20.59]]\n[[17.2]]\n[[15.01]]\n[[13.82]]\n[[11.35]]\n[[10.83]]\n[[9.9]]\n[[10.87]]\n[[15.94]]\n[[21.49]]\n[[29.59]]\n[[36.69]]\n[[44.73]]\n[[49.17]]\n[[50.87]]\n[[51.85]]\n[[48.49]]\n"
     ]
    }
   ],
   "source": [
    "col = 1\n",
    "while col <data.shape[1]:\n",
    "    print(MSE(data.iloc[:,col:col+1]).round(2))\n",
    "    col = col + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}